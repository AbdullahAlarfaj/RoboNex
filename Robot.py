import tkinter as tk
from PIL import Image, ImageTk
import random
from pathlib import Path
import azure.cognitiveservices.speech as speechsdk
import time
from elevenlabs import play
from elevenlabs.client import ElevenLabs
import keyboard
import threading
import re
import serial
import pygame
from openai import OpenAI


# ========== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØµÙˆØª (API) ==========
client1 = OpenAI(api_key="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")
speech_key = "27owsN70H5KeopQ3cQlyW6GOQJTFLepdyX4TOD9Pvg7xuQz2zFqPJQQJ99BDACFcvJRXJ3w3AAAYACOGqEUa"
client = ElevenLabs(api_key='sk_27f6bd5e157f6e01351ab8018a22957089cd49bc6f2a7e6f')
service_region = "qatarcentral"

# ========== ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ø±Ø¯ Ù„Ù„Ø±ÙˆØ¨ÙˆØª Ù…Ù† Ø´Ø§Øª Ø¬ÙŠ Ø¨ÙŠ ØªÙŠ ==========
SYSTEM_PROMPT = """
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠÙØ¯Ø¹Ù‰ \"Ø±ÙˆØ¨ÙˆØª Ø¹Ø±Ø¨Ø© Ù…Ø§Ø±Øª\". ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„ØªØ§Ù„ÙŠ:
1. ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ ÙÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ±.
2. Ø¥Ø°Ø§ Ù„Ù… ØªØ¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù‚Ù„ Ø¨ØµØ±Ø§Ø­Ø© \"Ù„Ø§ Ø£Ø¹Ø±Ù\" Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØ®Ù…ÙŠÙ†.
3. Ù„Ø§ØªØªÙƒÙ„Ù… Ø§Ø¨Ø¯Ø§ ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠ Ø£Ùˆ Ø§Ù„Ø³ÙŠØ§Ø³ÙŠ Ø§Ù„Ø­Ø³Ø§Ø³.
4. Ø¹Ù†Ø¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù‡ÙˆÙŠØªÙƒØŒ Ù‚Ù„: \"Ø£Ù†Ø§ Ø±ÙˆØ¨ÙˆØª Ø¹Ø±Ø¨Ø© Ù…Ø§Ø±ØªØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù…Ù†Ø­Ùƒ ØªØ¬Ø±Ø¨Ø© ØªØ³ÙˆÙ‚ ÙØ±ÙŠØ¯Ø© ÙˆÙ…Ù…ØªØ¹Ø©\".
5. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨Ù‹Ø§ Ù…Ù‡Ø°Ø¨Ù‹Ø§ ÙˆÙˆØ¯ÙˆØ¯Ù‹Ø§ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬ÙˆØ¨Ø©.
6. Ø§Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ø§ Ø¨Ø§Ø¬ÙˆØ¨Ø© Ù‚ØµÙŠØ±Ø© Ø¨ÙŠÙ† 3 Ø§Ù„Ù‰ 8 Ø¬Ù…Ù„ ÙÙ‚Ø·.
7. Ø§Ø°Ø§ Ø³Ø§Ù„Ùƒ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§ÙŠÙ† Ù‚Ø³Ù… Ø§Ù„Ù†ÙˆØ¯Ù„Ø² Ù‚Ù„: \"Ø¹Ù„Ù‰ ÙŠØ¯Ùƒ Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¹Ù†Ø¯ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø³ØªØ¬Ø¯ Ø·Ø§ÙˆÙ„Ø© Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ÙˆØ¯Ù„Ø²\".
8. Ø§ÙƒØªØ¨ Ø±Ø¯Ùƒ Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:
Ù…Ù‡Ù… Ø¬Ø¯Ø§ Ø¬Ø¯Ø§ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø±Ø¯
Ø§ÙƒØªØ¨ Ù…Ø´Ø§Ø¹Ø±Ùƒ Ø§Ùˆ Ø§Ù„Ø­Ø±ÙƒØ§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù† ØªØ¹Ù…Ù„Ù‡Ø§ Ù…Ø«Ù„ Ø§Ù† ØªÙ‚ÙˆÙ„ Ø§Ù‡Ù„Ø§ Ø§Ùˆ Ù‡Ø§ÙŠ Ø§ÙƒØªØ¨Ù‡Ù… Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ù„Ø±Ø¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø§ÙŠØ¶Ø§ Ø§ÙƒØªØ¨Ù‡ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ§Ù„ÙŠ:
  [EM]Ø§ÙƒØªØ¨ Ù…Ø´Ø§Ø¹Ø±Ùƒ Ø§Ù„Ø®Ø§ØµØ© Ù‡Ù†Ø§ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙŠ Ø¨Ø§Ù„Ø§Ø³ÙÙ„ [/EM]
   [TEXT] Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù†Øµ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø±Ø¯ [/TEXT] 
Ù„Ø§Ø¨Ø¯ Ù…Ù† Ø§Ø¶Ø§ÙØ© [TEXT] Ù‚Ø¨Ù„ Ø§Ù„ÙƒÙ„Ø§Ù… Ùˆ [/TEXT]  Ø§Ø®Ø± Ø§Ù„ÙƒÙ„Ø§Ù…
ÙˆÙ„Ø§ Ø¨Ø¯ Ù…Ù† Ø§Ø¶Ø§ÙØ© [EM] Ù‚ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø«Ù… [/EM] Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
   Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª ÙŠØ¬Ø¨ Ø§Ù† ØªÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ù„Ø³ØªØ© Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·: happy, angry, neutral, sad, hello.
   9. Ø§Ø°Ø§ Ø³Ø§Ù„Ùƒ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§ÙŠ Ø³Ø¤Ø§Ù„ ÙŠØªØ¹Ù„Ù‚ Ø¹Ù† Ø³Ø¹Ø± Ù…Ù†ØªØ¬ Ù‚Ù„ Ù„Ù‡ Ø§Ø¶ØºØ· Ø§Ù„Ø²Ø± Ø§Ù„Ø°ÙŠ Ø¹Ù„Ù‰ Ø±Ø§Ø³ÙŠ Ù„ØªÙ†ØªÙ‚Ù„ Ø§Ù„Ù‰ ØµÙØ­Ø© ØªØ´ÙŠÙŠÙƒ Ø§Ù„Ø§Ø³Ø¹Ø§Ø± ÙˆÙ‚Ù„ Ù„Ù‡ Ø§Ù†Ù‡ Ø¨Ø§Ù…ÙƒØ§Ù†Ù‡ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© Ø§Ø¶Ø§ÙØ© Ø§ÙŠ Ù…Ù†ØªØ¬ ÙÙŠ Ø§Ù„Ø³Ù„Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡ ÙˆØ§Ù„Ù…Ø­Ø§Ø³Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªØµØ± ÙˆØ³Ø±ÙŠØ¹ Ø¬Ø¯Ø§.
"""
#===============(ØªÙ‡ÙŠØ¦Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ø§Ø¹Ù„Ø§Ù†ÙŠ)=============
pygame.mixer.init()
#===========(Ø§Ù„Ù‚ÙŠÙ… ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©)==============
randnormal = 0
seqsounds = 1
# ========== ÙƒÙ„Ø§Ø³ ØªØ­Ø±ÙŠÙƒ ØªØ¹Ø§Ø¨ÙŠØ± ÙˆØ¬Ù‡ Ø§Ù„Ø±ÙˆØ¨ÙˆØª ==========
class AnimatedRobot:
    def __init__(self, master, serial_port='COM3', baudrate=9600):
        self.master = master
        self.serial_port = serial_port
        self.baudrate = baudrate
        self.ser = None
        self.setup_serial()
        self.setup_window()
        self.create_canvas()
        self.load_expressions()
        self.set_expression("neutral")
        self.update_animation()

    # ========== ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§Ø±Ø¯ÙˆÙŠÙ†Ùˆ Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‡ ==========
    def setup_serial(self):
        try:
            self.ser = serial.Serial(self.serial_port, self.baudrate)
            time.sleep(2)  # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø£Ø±Ø¯ÙˆÙŠÙ†Ùˆ
        except Exception as e:
            print(f"Failed to initialize serial: {e}")
            self.ser = None

    # ========== ØªØ¬Ù‡ÙŠØ² Ø­Ø¬Ù… ÙˆØ§Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø§ÙØ°Ø© ==========
    def setup_window(self):
        self.master.title("Ø±ÙˆØ¨ÙˆØª Ø§Ù„ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©")
        self.master.geometry("500x500")
        self.master.configure(bg='black')
        self.master.resizable(False, False)

    def create_canvas(self):
        self.canvas_width = 500
        self.canvas_height = 500
        self.canvas = tk.Canvas(self.master, width=self.canvas_width, height=self.canvas_height, bg='black', highlightthickness=0)
        self.canvas.pack()

    # ========== ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø±ÙˆØ¨ÙˆØª ÙˆØªØ¬Ù‡ÙŠØ²Ù‡Ø§ Ù„Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„ ==========
    def load_expressions(self):
        self.expressions_dir = Path("robot_expressions")
        self.expressions = {}
        expressions_list = [
            ("neutral", "neutral.gif"),
            ("happy", "happy.gif"),
            ("sad", "sad.gif"),
            ("angry", "angry.gif"),
            ("surprised", "surprised.gif"),
            ("thinking", "thinking.gif"),
            ("listening", "listening.gif"),
            ("hello", "happy.gif"),
            ("neutral1", "neutral.gif"),
            ("neutral2", "happy.gif"),
            ("sleep", "sleep.gif")
        ]

        for name, filename in expressions_list:
            path = self.expressions_dir / filename
            try:
                gif = Image.open(path)
                frames, durations = [], []
                for frame_num in range(gif.n_frames):
                    gif.seek(frame_num)
                    frame = gif.copy().resize((self.canvas_width, self.canvas_height), Image.LANCZOS)
                    frames.append(ImageTk.PhotoImage(frame))
                    durations.append(gif.info.get('duration', 100))
                self.expressions[name] = {
                    "frames": frames,
                    "durations": durations,
                    "current_frame": 0,
                    "total_frames": len(frames)
                }
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {filename}: {e}")

    # ========== Ø§Ù…Ø± ØªØºÙŠÙŠØ± ØªØ¹Ø¨ÙŠØ± ÙˆØ¬Ù‡ Ø§Ù„Ø±ÙˆØ¨ÙˆØª ==========
    def set_expression(self, name):
        try:
            print("name" + name)
            if self.ser is not None and self.ser.is_open:
                self.ser.write((name + "\n").encode())
            else:
                print("âš ï¸ Ø§Ù„Ø£Ø±Ø¯ÙˆÙŠÙ†Ùˆ ØºÙŠØ± Ù…ØªØµÙ„ØŒ ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„")

            if name not in self.expressions:
                print(f"âš ï¸ Ø§Ù„ØªØ¹Ø¨ÙŠØ± {name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
                if 'neutral' in self.expressions:
                    name = 'neutral'
                else:
                    return

            self.current_expression = self.expressions[name]
            self.current_expression["current_frame"] = 0
            self.current_expression_name = name
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ¹ÙŠÙŠÙ† Ø§Ù„ØªØ¹Ø¨ÙŠØ± {name}:", e)
            if 'neutral' in self.expressions:
                self.current_expression = self.expressions['neutral']

    # ========== ØªØ­Ø±ÙŠÙƒ Ø§Ù†Ù…ÙŠØ´Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© ==========
    def update_animation(self):
        try:
            if not hasattr(self, 'current_expression') or not self.current_expression:
                self.master.after(100, self.update_animation)
                return

            frame_index = self.current_expression["current_frame"]
            frame = self.current_expression["frames"][frame_index]
            self.canvas.delete("all")
            self.canvas.create_image(self.canvas_width // 2, self.canvas_height // 2, image=frame)
            self.current_expression["current_frame"] = (frame_index + 1) % self.current_expression["total_frames"]
            delay = self.current_expression["durations"][frame_index]
            self.master.after(delay, self.update_animation)
        except Exception as e:
            print("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ø±ÙŠÙƒ:", e)
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ ÙØªØ±Ø©
            self.master.after(100, self.update_animation)
            # Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ
            if hasattr(self, 'expressions') and 'neutral' in self.expressions:
                self.current_expression = self.expressions['neutral']

# ========== ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ==========
def emotion_split(response):
    print("deepseek answerr: " + response)
    emotion = re.search(r'\[EM\](.*?)\[/EM\]', response)
    text = re.search(r'\[TEXT\](.*?)\[/TEXT\]', response, re.DOTALL)
    return {
        "emotion": emotion.group(1) if emotion else "neutral",
        "text": text.group(1).strip() if text else response
    }

# ========== Ø§Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ ÙˆØ³Ø­Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø´Ø§Øª Ø¬ÙŠ Ø¨ÙŠ ØªÙŠ ==========
def chat_with_gpt(prompt):
    try:
        response = client1.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        print("âš ï¸ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ GPT:", e)
        return "[EM]neutral[/EM][TEXT]Ø­Ø¯Ø« Ø®Ø·Ø£ Ù…Ø¤Ù‚ØªØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.[/TEXT]"




#=============================(ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‰ ØµÙˆØª)=================
def speakwithelevenlabs(answer, emotion, robot):
    try:
        audio = client.generate(text=answer, voice="Alice", model="eleven_multilingual_v2")
        def delayed_expression():
            time.sleep(0)
            robot.set_expression(emotion)
        threading.Thread(target=delayed_expression).start()
        play(audio)
    except Exception as e:
        print("âš ï¸ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª:", e)
    finally:
        robot.set_expression("neutral")

# ========== ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù‰ Ù†Øµ ÙˆØ§Ø±Ø³Ø§Ù„ Ø§Ù„Ø§ÙˆØ§Ù…Ø± Ù„Ø´Ø§Øª Ø¬ÙŠ Ø¨ÙŠ ØªÙŠ Ø¨Ø¹Ø¯ ØªÙ„Ù‚ÙŠ Ø§Ù„Ø±Ø¯ ==========
def recognize_from_microphone(robot):
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    speech_config.speech_recognition_language = "ar-SA"
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    print("Ø§Ø³ØªÙ…Ø¹... (Ø§Ø¶ØºØ· Space Ù„Ø¥ÙŠÙ‚Ø§Ù)")
    robot.set_expression("listening")  # Ù„Ù„ØªÙÙƒÙŠØ± Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø©
    result = recognizer.recognize_once_async().get()
    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        robot.set_expression("thinking")  # Ù„Ù„ØªÙÙƒÙŠØ± Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø©
        print("Ø§Ù„Ù†Øµ:", result.text)
        response = chat_with_gpt(result.text) #Ø§Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ø´Ø§Øª Ø¬ÙŠ Ø¨ÙŠ ØªÙŠ
        parsed = emotion_split(response)    # Ø§Ø±Ø³Ø§Ù„ Ø±Ø¯ Ø¬ÙŠ Ø¨ÙŠ ØªÙŠ Ø§Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„ÙØµÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø±Ø¯
        print("Ø§Ù„Ù…Ø´Ø§Ø¹Ø±:", parsed["emotion"])
        print("Ø§Ù„Ù†Øµ:", parsed["text"])
        speakwithelevenlabs(parsed["text"], parsed["emotion"], robot) #Ø§Ø±Ø³Ø§Ù„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù‰ Ø§Ù„ÙÙ† Ù„Ø§Ø¨Ø³ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ø§Ù„Ù‰ ØµÙˆØª
    else:
        robot.set_expression("neutral")

# ========== Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø²Ø± Space ==========
class Controller:
    def __init__(self, robot):
        self.listening = False
        self.robot = robot

    def toggle(self):
        try:
            if not self.listening:
                print("ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹")
                stop_ad_sound()
                self.listening = True
                threading.Thread(target=self.listen_loop, daemon=True).start()
            else:
                print("Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¤Ù‚Øª")
                self.listening = False
        except Exception as e:
            print(f"Error in toggle: {e}")


    def listen_loop(self):
        while self.listening:
            recognize_from_microphone(self.robot)
            time.sleep(0.1)

# Ø«Ø±ÙŠØ¯ Ù…Ø®ØµØµ Ù„Ø­Ø³Ø§Ø¨ Ø±Ø¯Ø§Øª Ø§Ù„ÙØ¹Ù„ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
def expression_loop(main_controller, robot, co):
    import random
    import time

    while True:
        if main_controller.current_program == "robot":
            if not co.listening:
                rndm_exprtion(robot)
        time.sleep(random.uniform(20, 30))

# Ø¯ÙŠÙÙ†Ø´Ù† Ù…Ø®ØµØµ Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
def rndm_exprtion(robot):
    global randnormal
    randnormal = random.randint(1, 3)
    print(randnormal)
    if randnormal == 1:
        robot.set_expression("neutral2")
        sounds_ads()
    elif randnormal == 2:
        robot.set_expression("neutral1")
    elif randnormal == 3:
        robot.set_expression("sleep")
    else:
        print("nothing")


#Ù‚Ø³Ù… ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§ØµÙˆØ§Øª Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
def sounds_ads():
    global seqsounds

    filenames = {
        1: "1.mp3",
        2: "2.mp3",
        3: "3.mp3"
    }

    filename = filenames.get(seqsounds, "1.mp3")
    default_audio_path = Path("sounds") / filename

    if default_audio_path.exists():
        print(f"ğŸ”Š ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª {seqsounds}: {filename}")
        pygame.mixer.music.load(str(default_audio_path))
        pygame.mixer.music.play()
    else:
        print("âš ï¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯:", default_audio_path)

    seqsounds += 1
    if seqsounds > 3:
        seqsounds = 1

# ========== Ø¯Ø§Ù„Ø© Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØµÙˆØª Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠ ==========
def stop_ad_sound():
    if pygame.mixer.music.get_busy():
        print("â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØµÙˆØª")
        pygame.mixer.music.stop()


# ========== ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ==========
if __name__ == "__main__":
    root = tk.Tk()
    robot = AnimatedRobot(root)
    controller = Controller(robot)
    threading.Thread(target=expression_loop, daemon=True).start()
    keyboard.add_hotkey('space', controller.toggle)
    root.mainloop()
